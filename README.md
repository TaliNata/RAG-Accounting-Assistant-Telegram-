# RAG-бот для Telegram: ответы на вопросы по бухгалтерии и расчёту зарплаты на основе корпоративной базы знаний.

Бухгалтерский домен — **high-stakes**: ошибка в расчёте НДФЛ или отпускных имеет прямые финансовые последствия. Этим кейс отличается от типичных RAG-демо на абстрактных PDF: здесь точность ответа критична, а галлюцинация недопустима.

---

## Архитектура

```
knowledge_base.md / docs/*.md
        │
        ▼
  Paragraph chunking
  (chunk_size=400, overlap=80)
        │
        ▼
  Эмбеддинги: paraphrase-multilingual-MiniLM-L12-v2
  (sentence-transformers, поддержка русского)
        │
        ▼
  ChromaDB (PersistentClient, локально)
        │
  Вопрос пользователя → эмбеддинг → top-4 retrieval
        │
        ▼
  System prompt + контекст + вопрос → GPT-4o-mini
        │
        ▼
  Ответ в Telegram
```

---

## Prompt-решения и их обоснование

### System prompt

```
Ты помощник по бухгалтерии и расчёту зарплаты.
Отвечай кратко и по существу только на основе приведённого контекста.
Если в контексте нет ответа — так и скажи.
Язык ответа: русский.
```

**Почему именно так:**

| Решение | Обоснование |
|---|---|
| `только на основе приведённого контекста` | Прямой запрет галлюцинаций — модель не домысливает проценты, суммы, сроки |
| `если в контексте нет ответа — так и скажи` | Явное разрешение на отказ лучше, чем молчаливая галлюцинация |
| `отвечай кратко и по существу` | Бухгалтерский вопрос требует точного ответа, не эссе |
| `temperature=0.3` | Низкая температура = меньше творчества, больше воспроизводимости |

### Чанкинг

Разбивка по абзацам (не по фиксированному числу символов) с перекрытием 80 символов. Бухгалтерские регламенты структурированы по пунктам — абзацный чанкинг сохраняет смысловую целостность правила в одном фрагменте.

### Retrieval

`top_k=4` — эмпирически подобранный баланс: достаточно контекста для составного вопроса (например, «как считаются отпускные при неполном месяце»), но не перегружает контекстное окно.

### Выбор модели эмбеддингов

`paraphrase-multilingual-MiniLM-L12-v2` — лёгкая (≈117MB), работает локально без API, показывает достаточное качество на русскоязычных документах для domain-specific retrieval.

---

## Пример диалога

```
Пользователь: Как рассчитываются отпускные?

[Retrieval нашёл фрагменты об среднедневном заработке, расчётном периоде, исключаемых периодах]

Бот: Отпускные рассчитываются исходя из среднедневного заработка,
умноженного на количество дней отпуска. Среднедневной заработок
определяется за 12 календарных месяцев до начала отпуска.
Из расчётного периода исключаются дни болезни, командировок
и другие периоды, когда сохранялся средний заработок.
```

```
Пользователь: Какой процент НДФЛ для нерезидентов?

[Если информация отсутствует в knowledge_base.md]

Бот: В базе знаний нет информации по этому вопросу.
Рекомендую уточнить у главного бухгалтера или в НК РФ ст. 224.
```

---

## Стек

- `python-telegram-bot` — Telegram-интеграция
- `chromadb` — векторное хранилище (персистентное, локально)
- `sentence-transformers` — эмбеддинги (без внешнего API)
- `openai` — GPT-4o-mini для генерации ответа
- `python-dotenv` — конфигурация через `.env`

---

## Установка и запуск

```bash
python -m venv venv
venv\Scripts\activate      # Windows
# source venv/bin/activate # Linux/Mac
pip install -r requirements.txt
```

Скопируйте `.env.example` в `.env`:

```env
TELEGRAM_BOT_TOKEN=ваш_токен_от_BotFather
OPENAI_API_KEY=sk-...
```

Положите базу знаний в `rag/knowledge_base.md` (и/или дополнительные файлы в `rag/docs/`).

```bash
python bot.py
```

При первом запуске автоматически скачается модель эмбеддингов и построится ChromaDB-индекс.

---

## Структура проекта

```
├── bot.py                  # Telegram-хендлеры
├── rag/
│   ├── rag_utils.py        # Чанкинг, эмбеддинги, retrieval, LLM-вызов
│   ├── knowledge_base.md   # База знаний (бухгалтерские регламенты)
│   ├── docs/               # Дополнительные документы (опционально)
│   └── chroma_db/          # Персистентный векторный индекс (генерируется)
├── .env.example
└── requirements.txt
```

---

## Известные ограничения и решения

**Проблема:** Региональные ограничения OpenAI API в некоторых средах.  
**Решение в коде:** Graceful degradation — при недоступности LLM бот возвращает сырые фрагменты из retrieval вместо падения.

**Проблема:** Бухгалтерские вопросы часто составные («как считать отпускные при увольнении в середине месяца»).  
**Решение:** `top_k=4` + overlap при чанкинге увеличивают шанс захватить все релевантные правила в одном запросе.
